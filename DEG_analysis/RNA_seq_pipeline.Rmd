---
title: "RNA_Seq_Pipeline"
author: "Mari Johnson"
date: '2022-08-29'
output: html_document
---

```{r Rmd setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, error = TRUE)
knitr::opts_knit$set(root.dir = '/home/mari/RNA/Daniel') #Permanently sets wd for Rmd
```
### Aims;

1) To pre-process RNAseq data for typhoid challenge/vaccination studies
2) To run differential gene expression analysis at a global and gene level scale

### Overview of chapters

1) Pre-processing
- Read and structure count data
- Remove lowly expressed genes
- Transform and normalise data
- Limma Voom

2) Differential gene expression analysis
- Create design matrix
- Fit linear model for comparisons of interest
- Examine differentially expressed genes
- Visualise comparisons with volcano plots

3) Spline gene modelling 
- Re-organise normalised RNAseq data from voom object
- Fit splines model to gene expression values over time course
- Visualise changes in gene expression using fitted splines/box plots
- Test for statistical significance


Source Materials:
- https://ucdavis-bioinformatics-training.github.io/2018-June-RNA-Seq-Workshop/thursday/DE.html
- https://www.bioconductor.org/packages/devel/workflows/vignettes/RNAseq123/inst/doc/limmaWorkflow.html
- https://www.youtube.com/watch?v=z36fu178jIQ&ab_channel=LiquidBrainBioinformatics



## 1) Pre-processing

```{r Set Directories}
setwd("~/RNA/Daniel") #where data is saved

plot_dir <- c("~/GWAS_22/new_gwas/Plots/DEG/pre-process/") #where to save output plots

#load packages #
library(dplyr)
library(data.table)
library(tidyr)
library(tidylog)
library(limma)
library(stringi)
library(janitor)
library(stringr)
library(splines)
library(edgeR)
library(BiocManager)
library(DESeq2)
library(Glimma)
library(RColorBrewer)
```

### Set up and tidy data

```{r Set up Data}
load("Filter2_VAST_STAR_HTSeq_gene_meta_autosomes_mismatch_corrected_demo_minus_rRNA_globins_autosomes_2021-04-27.R")

data <- VAST_autosomes #RNAseq data set
rm(VAST_autosomes)

samp <- data$samples
exprs <- data$counts
symbol <- data$gene
pData <- data$meta_data
```

```{r Tidy Data, results='hide'}

#Clean names using janitor package
str(data$meta_data)
data$meta_data <- clean_names(data$meta_data)
#Rename variables'
names(data$meta_data)[names(data$meta_data) == "days_since_challenge"] <- "time"
#Clean duplicate gene names (these cause trouble later if not!)
rownames(exprs) <- make_clean_names(rownames(exprs))
#Remove NA participant IDs (these are in y - transfer over)
#colnames(data$meta_data)<-gsub("_x","",colnames(data$meta_data))
colnames(data$meta_data) <- stri_replace_all_regex(colnames(data$meta_data),
                                  pattern=c('_x', 'x_',
                                            '_e2_c3', 'e3_c3', 'e5_c5'),
                                  replacement=c(''),
                                  vectorize=FALSE)

```
### Filter and normalise genes

Low expressed genes will be unreliable/not worth testing so remove these low count genes
Additionally need to normalise data to account for library size/gene counts

```{r Calculate log counts/per million}
#Convert counts to log to minimise the effect of small values and negatives
cpm <- cpm(data)
lcpm <- cpm(data, log=TRUE) #Used for exploratory plots/checks

L <- mean(data$samples$lib.size) * 1e-6 #average library size
M <- median(data$samples$lib.size) * 1e-6
c(L, M)# tells us the median/mean log2 counts per million (11.8)

```
```{r Remove Lowly expressed genes}
#Remove genes with no counts
table(rowSums(data$counts==0)==521)
#Samples with row sum = 0 across all samples,
#13609 samples

#Filter low values using edgeR algorithm
keep.exprs <- filterByExpr(data)
# Warning - all samples appear to belong to the same group
data2 <- data[keep.exprs, keep.lib.sizes=FALSE] #subset og data
dim(data2)
#Now there are 12969 genes across 514 participants
```

```{r Visualise raw and filtered count data, warning=FALSE}
#Visualise the frequency of counts across study before and after filtering
lcpm.cutoff <- log2(10/M + 2/L)
nsamples <- ncol(data) #521/514
col <- brewer.pal(nsamples, "Paired")
par(mfrow=c(1,2))

#Plot Raw Log-cpm against density
plot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,0.26), las=2, main="", xlab="")
title(main="A. Raw data", xlab="Log-cpm")
abline(v=lcpm.cutoff, lty=3)
for (i in 2:nsamples){
  den <- density(lcpm[,i])
  lines(den$x, den$y, col=col[i], lwd=2)
}

#Plot filtered version
lcpm <- cpm(data2, log=TRUE)
plot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,0.26), las=2, main="", xlab="")
title(main="B. Filtered data", xlab="Log-cpm")
abline(v=lcpm.cutoff, lty=3)
for (i in 2:nsamples){
  den <- density(lcpm[,i])
  lines(den$x, den$y, col=col[i], lwd=2)
}
#Also can plot as boxplots (see RNAseq_setup.R)
#Keep filtered data as main DF
data <- data2
rm(data2)
```
### MDS plot 

- Visually examine the factors to include in you linear modelling
- These could include technical factors such as sequencing lane/batch and also experimental factors such as time points/diagnosis
- Ideally you would want to see differences in time points where we expect to see DEG's, and less variation between technical factors
- If there is no clustering then that factor is not necessary for the lm
- You can also test for two factors together using interaction terms, e.g
 group = interaction(data$meta_data$sequence_pool,data$meta_data$TimePoint)

```{r MDS plot}
#Calc norm factors before MDS plot

#Normalise data ###
data <- calcNormFactors(data, method = "TMM")#Normalises count data via TMM scale
#?calcNormFactors
#Sequencing lane check
group = as.factor(data$meta_data$sequence_pool)
#Set up group to plot/colours
lcpm<-cpm(data,log=TRUE)
col.group <-group
levels(col.group) <-brewer.pal(nlevels(col.group),"Accent")
col.group<-as.character(col.group)

#Plot MDS (Post-norm)
pdf(paste(plot_dir,"sequence_pool.pdf",sep =""))
plotMDS(lcpm,labels=group,col=col.group)
title(main= "Sequencing Pool")
dev.off()

#VAST notes: 
#Quite a strong batch effect
#Will need to account for this technical variation as a covar in any models

```
#### Batch correction Notes:

From MDS plot we can see a significant batch effect in sequencing pool
You can account for batch corrections using limma (this might be useful for raw data in splines model later) e.g limma::removeBatchEffect(cpm, data$meta_data$sequence_pool)
Remove batch effect from raw counts and then reconvert to lcpm to get rid of negative value, which disturb the model. Re-normalise batch corrected values?

But for DEG analysis just include sequencing_pool as a co-variate in the model

```{r Time point MDS, message=FALSE}

#Time point MDS
group = as.factor(data$meta_data$time_point3)
col.group<-group
#Set colours
palette_Dark2 <- colorRampPalette(brewer.pal(8, "Set2"))
levels(col.group)<-palette_Dark2(length(unique(data$meta_data$time_point3)))
col.group<-as.character(col.group)
#Plot MDS
pdf(paste(plot_dir,"time_mds.pdf",sep =""))
#starts writing a PDF to file
plotMDS(lcpm,labels=group,col=col.group)
title(main= "Time Point") #Some clustering around TD already :)
dev.off()

```
```{r Vaccine MDS, message=FALSE}
#Time point MDS
group = as.factor(data$meta_data$study_arm)
col.group<-group
#Set colours
palette_Dark2 <- colorRampPalette(brewer.pal(8, "Set2"))
levels(col.group)<-palette_Dark2(length(unique(data$meta_data$time_point3)))
col.group<-as.character(col.group)
#Plot MDS
pdf(paste(plot_dir,"vaccine_mds.pdf", sep =""))
#starts writing a PDF to file
plotMDS(lcpm,labels=group,col=col.group)
title(main= "Vaccination status") #Some clustering around TD already :)
dev.off()
```


## 2) Differential gene expression analysis

#### Design Matrix

Generally, data preparation for DEG analysis utilises all the samples in your study, even the ones that you might not care about using or comparing initially, and keeps them in a matrix format (this allows R to easily subset conditions, based on matching row or column indices).

Now at the start of your analysis, you might have an idea of some comparisons you would like to make, let's say the difference between vaccinated and non-vaccinated samples. (ignore time points for now)

We want to model the average difference (fold change) in gene expression between these two groups.
E.g `lm(exprs_data ~ vaccine_group)`

However, if one group had for example an older average participant age, or a technical batch differences that would skew the results, we want to include these factors as covariates in our model as such:

`lm(exprs_data ~ vaccine_group + age + sex)`


The *design matrix* runs across all our samples, and notes down the corresponding model parameters extracted from the orginal S4 data$metadata, i.e vaccine group, age, sequence_pool
It is set up so that rows are associated with samples and columns are associated with the specified model parameters.

```{r, echo=FALSE}
# Define variable containing url
url <- "https://f1000researchdata.s3.amazonaws.com/manuscripts/30844/e0cd78d8-1ebb-48d6-a35c-007d3d42961c_figure2.gif"
#html code to place and size below inline text
```
<center><img src="`r url`"></center>


```{r Design Matrix, results='hide'}
#Check metadata variable names/data types for design 
#Design matrix can't have duplicate column names, weird symbols etc
pData <- data$meta_data
str(pData)

#Change sequence pool to factor
data$meta_data$sequence_pool <- as.factor(data$meta_data$sequence_pool)

#Model design matrix
design <- model.matrix(~0 + time_point3 + diagnosis + age_at_do + sex + vaccine + sequence_pool,data = data$meta_data)

#Remove null variables, i.e = all 0s or NAs
design <- design[,-(colSums(design) == 0)]
#design <- test[,-c(9:10)]

#Tidy new design colnames
colnames(design)<-gsub("vaccine","",colnames(design))
colnames(design)<-gsub("time_point3","",colnames(design))

```


### Limma Voom

Limma uses linear modelling on log-CPM values to model gene expression from RNAseq data, an assumption of the model is that the errors/residuals/variance are normally distributed.
However, it has been established that for RNAseq data there is a non-linear relationship between the number of counts of a given gene, and the variance of those counts.
Because the variance is unequal across a range of values, i.e the data is heteroskedastic, we have to normalise this unequal variance.
The voom function normalises/adjusts variance so it is no longer dependent on count size, and we can model gene expression accurately in future steps.

As the voom function is normalising the residuals around a fitted model, we need to input the design matrix as described in section 2, which specifies linear model variables, to perform voom accordingly


```{r Voom}
#Plots mean count size (x) against variance (y)
#Lower counts tend to have lower variance
#Therefore voom normalises - flattens this trend
#Variances are calculated by fitting a linear model to the data provided by the design matrix

```

Typically voom plot shows higher variance for lower counts. If filtering was not performed properly,a drop in variance levels can be observed at the low end of the expression scale due to very small counts. Experiments with high biological variation tend to result in flatter trends, lower biological variation tend to have sharper trends.

When modelling gene expression between conditions using design/contrast matricies, we can now use our corrected data in the voom object (S4), and visually check that we have removed the variance trend with log expression. 


### Contrast Matrix

Our contrast matrix will go through all of our samples and indicate whether a sample is to be compared, and which group it belongs to.
It sets this up as so that rows are associated with model parameters and colums represent the contrast of interest

Our design matrix indicates to the linear model 
